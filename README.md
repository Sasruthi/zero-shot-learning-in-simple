# zero-shot-learning-in-simple

Implementation of Zero shot learning ,NLP for categorization of the given input text.
Hugging Face API along with BERT transformer is used to perform the classification.
BERT - Bidirectional Encoder Representations from Transformers
BERT is used because it tends to generate contextualized embeddings. It looks at the statementâ€™s context and generates a meaningful vector representation for a given word.

BERT Large is a huge model using 24 encoder layers.
BERT large is used for this categorization of text to their domain .
Here facebook , bart large mnli model is used.

Here the model has correctly classified the sentence as category of technology with 99% accuracy.i.e,with accuracy score 0.99150550365448.
